---
name: task-type-test-generation
description: Generate test cases from technical design before implementation. Follows TDD approach - write tests first, then implement. Use after Technical Design, before Code Implementation.
---

# Task Type: Test Generation

## Purpose

Generate comprehensive test cases from technical design specifications. This follows TDD (Test-Driven Development) - tests are written BEFORE implementation.

---

## Important Notes

### Skill Prerequisite
- If you HAVE NOT learned `task-execution-guideline` skill, please learn it first before executing this skill.

**Important:** If Agent DO NOT have skill capability, can directly go to `.github/skills/` folder to learn skills. And SKILL.md file is the entry point to understand each skill.

---

## Task Type Default Attributes

| Attribute | Value |
|-----------|-------|
| Task Type | Test Generation |
| Category | @feature-stage |
| Next Task Type | Code Implementation |
| Require Human Review | No |
| Feature Phase | Test Generation |

---

## Skill Output

This skill MUST return these attributes to the Task Data Model:

```yaml
Output:
  status: completed | blocked
  next_task_type: Code Implementation
  require_human_review: No
  task_output_links: [tests/]
  
  # Feature stage dynamic attributes (REQUIRED)
  category: @feature-stage
  feature_id: FEATURE-XXX
  feature_title: {title}
  feature_version: {version}
  feature_phase: Test Generation
```

---

## Definition of Ready (DoR)

| # | Checkpoint | Required |
|---|------------|----------|
| 1 | Technical design document approved | Yes |
| 2 | Acceptance criteria defined | Yes |
| 3 | Interface specifications exist | Yes |
| 4 | Test framework available in project | Yes |
| 5 | Test patterns/conventions documented | No |

---

## Execution Procedure

### Step 1: Review Technical Design

```
1. Load technical design document
2. Extract testable components:
   - Public interfaces
   - Method signatures
   - Input/output contracts
   - Error conditions
   - Edge cases
3. Map to acceptance criteria
```

### Step 2: Design Test Strategy

```
1. Categorize tests needed:
   - Unit tests (isolated components)
   - Integration tests (component interactions)
   - API tests (endpoint validation)
   
2. Prioritize:
   - Core functionality first
   - Happy path before edge cases
   - Critical paths before optional

3. Define test data requirements
```

### Step 3: Generate Unit Tests

**For each component/function:**

```
1. Test happy path:
   - Valid inputs
   - Expected outputs
   - Normal conditions

2. Test edge cases:
   - Boundary values
   - Empty inputs
   - Maximum values

3. Test error conditions:
   - Invalid inputs
   - Missing dependencies
   - Exception handling
```

**Test Structure:**
```
test_<function>_<scenario>_<expected_result>
  GIVEN: <preconditions>
  WHEN: <action>
  THEN: <expected outcome>
```

### Step 4: Generate Integration Tests

```
1. Identify integration points:
   - Component A → Component B
   - Service → Database
   - API → External service

2. For each integration:
   - Test successful flow
   - Test failure handling
   - Test timeout/retry behavior
```

### Step 5: Test Documentation

```
1. Document test coverage:
   | Component | Unit Tests | Integration Tests |
   |-----------|------------|-------------------|
   | <name>    | X tests    | Y tests           |

2. Document test data:
   - Mock data definitions
   - Test fixtures
   - Setup/teardown requirements

3. Document known gaps (if any)
```

### Step 6: Verify Tests

```
1. Run all tests:
   - All should FAIL (code not written yet)
   
2. Verify failure reasons:
   - Should fail due to missing implementation
   - NOT due to test errors

3. Fix any test syntax/setup issues
```

---

## Definition of Done (DoD)

| # | Checkpoint | Required |
|---|------------|----------|
| 1 | Unit tests cover all public interfaces | Yes |
| 2 | Integration tests cover main flows | Yes |
| 3 | Tests follow project conventions | Yes |
| 4 | All tests fail for right reason | Yes |
| 5 | Test coverage documented | Yes |

**Important:** After completing this skill, always return to `task-execution-guideline` skill to continue the task execution flow and validate the DoD defined there.

---

## Task Completion Output

Upon completion, return:
```yaml
feature_id: {Feature ID}
feature_status: {In|Done} {Feature Phase}
category: {Category}
next_task_type: {Next Task Type}
require_human_review: {Require Human Review}
task_output_links:
  - tests/unit/{feature-tests}
  - tests/integration/{feature-tests}
```

---

## Test Generation Templates

### Unit Test Template

```javascript
describe('<Component>', () => {
  describe('<method>', () => {
    it('should <expected behavior> when <condition>', () => {
      // GIVEN
      const input = ...;
      
      // WHEN
      const result = component.method(input);
      
      // THEN
      expect(result).toBe(expected);
    });
  });
});
```

### Integration Test Template

```javascript
describe('<Feature> Integration', () => {
  beforeAll(async () => {
    // Setup test environment
  });

  afterAll(async () => {
    // Cleanup
  });

  it('should <end-to-end behavior>', async () => {
    // GIVEN
    // WHEN
    // THEN
  });
});
```

---

## Patterns

### Pattern: Acceptance Criteria → Tests

**When:** Clear acceptance criteria exist
**Then:**
```
FOR EACH acceptance criterion:
  1. Create at least one test
  2. Test name reflects criterion
  3. Assert exact expected behavior
```

### Pattern: Interface → Tests

**When:** Technical design has interface specs
**Then:**
```
FOR EACH public method:
  - 1 happy path test
  - 1+ edge case tests
  - 1+ error tests
```

### Pattern: Test Coverage Target

**When:** Setting test goals
**Then:**
```
Target coverage:
- Public methods: 100%
- Core business logic: 90%+
- Edge cases: Best effort
- Error handling: 80%+
```

---

## Anti-Patterns

| Anti-Pattern | Why Bad | Do Instead |
|--------------|---------|------------|
| Test implementation details | Brittle, breaks on refactor | Test behavior only |
| Write tests after code | Misses TDD benefits | Write tests first |
| One giant test | Hard to debug | One assertion per test |
| Test private methods | Couples to internals | Test via public interface |
| Skip edge cases | Bugs hide in edges | Prioritize edge cases |
| Hardcoded test data | Hard to maintain | Use test fixtures |

---

## Code Quality Checklist

Before completing test generation:

| # | Check | ✅ |
|---|-------|---|
| 1 | Tests are independent (no order dependency) | |
| 2 | Test names are descriptive | |
| 3 | Assertions are specific | |
| 4 | Mock data is realistic | |
| 5 | Setup/teardown is clean | |
| 6 | Tests will help debug (good error messages) | |

---

## Example

**Feature:** FEATURE-001 User Service

**Technical Design Input:**
```
UserService:
  - createUser(userData): User
  - getUser(userId): User | null
  - updateUser(userId, updates): User
  - deleteUser(userId): boolean

Constraints:
  - Email must be unique
  - Name is required
  - UserId is UUID
```

**Execution:**
```
1. Execute Task Flow from task-execution-guideline skill

2. DoR Check:
   - Technical design approved ✓
   - Acceptance criteria defined ✓

3. Generate Tests:

   describe('UserService', () => {
     describe('createUser', () => {
       it('should create user with valid data', () => {...});
       it('should throw error when email exists', () => {...});
       it('should throw error when name is missing', () => {...});
       it('should generate UUID for new user', () => {...});
     });

     describe('getUser', () => {
       it('should return user when exists', () => {...});
       it('should return null when not found', () => {...});
       it('should throw error on invalid UUID format', () => {...});
     });

     describe('updateUser', () => {
       it('should update user fields', () => {...});
       it('should throw error on duplicate email', () => {...});
       it('should throw error when user not found', () => {...});
     });

     describe('deleteUser', () => {
       it('should return true when deleted', () => {...});
       it('should return false when not found', () => {...});
     });
   });

4. Test Coverage:
   | Component | Unit Tests | Status |
   |-----------|------------|--------|
   | createUser | 4 | ✅ |
   | getUser | 3 | ✅ |
   | updateUser | 3 | ✅ |
   | deleteUser | 2 | ✅ |
   | **Total** | **12** | **All failing (TDD ready)** |

5. Return Task Completion Output:
   feature_id: FEATURE-001
   feature_status: Done Test Generation
   category: @feature-stage
   next_task_type: Code Implementation
   require_human_review: No
   task_output_links:
     - tests/unit/services/user.service.test.js

6. Resume Task Flow from task-execution-guideline skill
```
